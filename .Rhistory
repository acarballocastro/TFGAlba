2004, 2013, 2003, 1999, 1999)
length(mesura)
cargol <- factor(rep(rep(1:3,each=3),3))
cargol
vascula <- factor(rep(1:3, each = 9))
vascula
data.frame(mesura, cargol, vascula)
resultats <- mixlm::lm(mesura ~ r(cargol)*r(vascula))
Anova(resultats, type="III")
Anova(resultats, type="III")$var.comps
rendiment <- c(66, 64, 63, 57, 60, 56, 62, 62, 58, 54, 73, 72, 42, 39, 47, 42,
39, 40, 47, 35, 44, 48, 51, 51, 31, 40, 44, 34, 34, 36, 25, 36,
43, 30, 54, 46)
centre <- factor(rep(1:3, each=12))
centre
entrenador <- factor(rep(1:3,each=4,3))
entrenador
data.frame(centre, entrenador)
resultats <- mixlm::lm(rendiment ~ r(centre) + r(entrenador)%in%r(centre))
Anova(resultats, type="III")
sum(Anova(resultats, type="III")$var.comps)
comb <- interaction(presion, temp)
# bartlett.test(res ~ presion)
# bartlett.test(res ~ temp)
bartlett.test(res ~ comb)
install.packages("flexdashboard")
library(flexdashboard)
library(renv)
install.packages("renv")
library(flexdashboard)
library(tidyverse)
library(readr)
read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/alcohol-consumption/drinks.csv")
datos1 = read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/alcohol-consumption/drinks.csv")
View(datos1)
datos1
datos12 = read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/alcohol-consumption/drinks.csv", cols = (country = col_factor(), .default = col_integer(),
total_litres_of_pure_alcohol = col_double()))
datos12 = read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/alcohol-consumption/drinks.csv", col_types = cols(.default = col_integer(), country = col_factor(), total_litres_of_pure_alcohol = col_double()))
datos12
install.packages("installr")
library(installr)
updateR()
updateR()
list.of.packages <- c("tidyverse", "nycflights13")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(tidyverse)
library(nycflights13)
data(flights, package = "nycflights13")
flights
head(flights)
flights %>%
filter(arr_time > 2*60)
flights %>%
filter(arr_delay > 2*60)
flights %>%
filter(origin %in% c("IAH", "HOU"))
flights
View(flights)
View(flights)
flights %>%
filter(dest %in% c("IAH", "HOU"))
flights %>%
filter(carrier %in% c("AA", "DL", "UA"))
flights %>%
filter(month %in% c(7,8,9))
View(flights)
flights %>%
filter(dep_delay == 0 $& arr_delay > 2*60)
flights %>%
filter(dep_delay == 0 & arr_delay > 2*60)
flights %>%
filter(between(dep_time, 0, 600))
flights %>%
arrange(., desc(distance))
flights %>%
arrange(., desc(distance))
flights %>%
arrange(distance)
flights %>%
arrange(distance) %>%
slice(1:10)
flights %>%
arrange(arr_delay) %>%
slice(1:10)
flights %>%
arrange(arr_delay, desc()) %>%
slice(1:10)
flights %>%
arrange(arr_delay, desc(arr_delay)) %>%
slice(1:10)
flights %>%
arrange(arr_delay, desc(arr_delay))
flights %>%
arrange(desc(arr_delay)) %>%
slice(1:10)
flights %>%
arrange(desc(arr_delay)) %>%
slice(1:5)
flights %>%
arrange(desc(arr_delay)) %>%
head(5)
flights %>%
arrange(desc(air_time/distance)) %>%
head(5) # Otra forma para seleccionar los 5 primeros
flights %>%
arrange(air_time/distance) %>%
head(5) # Otra forma para seleccionar los 5 primeros
flights %>%
arrange(desc(air_time/distance)) %>%
head() # Otra forma para seleccionar los 5 primeros
flights %>%
arrange(desc(air_time/distance)) %>%
head(1) # Otra forma para seleccionar los 5 primeros
flights %>%
arrange(!is.na(dep_time), dep_time)
flights
dep_time/100
flights$dep_time/100
floor(flights$dep_time/100)
flights %>%
mutate(dep_time_mid = floor(dep_time/100)*60)
flights %>%
mutate(dep_time_mid = floor(dep_time/100)*60 + (dep_time - floor(dep_time/100)*100))
flights$dep_time_mid
flights %>%
transmute(dep_time_mid = floor(dep_time/100)*60 + (dep_time - floor(dep_time/100)*100))
flights
flights %>%
transmute(dep_time_mid = floor(dep_time/100)*60 + (dep_time - floor(dep_time/100)*100),
sched_dep_time_mid = floor(sched_dep_time/100)*60 + (sched_dep_time - floor(sched_dep_time/100)*100))
library(tidyverse)
library(nycflights13)
data(flights, package = "nycflights13")
head(flights)
View(flights)
View(flights)
flights %>%
mutate(sched_dep_time_mid = hour*60 + minute,
dep_time_mid = hour*60 + minute + dep_delay)
flights %>%
mutate(sched_dep_time_mid = hour*60 + minute,
dep_time_mid = hour*60 + minute + dep_delay) %>%
select(dep_time, dep_time_mid, sched_dep_time, sched_dep_time_mid, hour, minute, dep_delay)
flights %>%
mutate(dep_time_mid = floor(dep_time/100)*60 + (dep_time - floor(dep_time/100)*100),
sched_dep_time_mid = floor(sched_dep_time/100)*60 + (sched_dep_time - floor(sched_dep_time/100)*100)) %>%
select(dep_time, dep_time_mid, sched_dep_time, sched_dep_time_mid)
flights %>% group_by(day) %>%
first(dep_time)
flights %>% group_by(day, dep_time) %>%
first(dep_time)
flights %>% group_by(day) %>%
summartise(primer_vuelo = first(dep_time),
ultimo_vuelo = last(dep_time))
flights %>% group_by(day) %>%
summarise(primer_vuelo = first(dep_time),
ultimo_vuelo = last(dep_time))
flights %>% group_by(day) %>%
summarise(primer_vuelo = first(!is.na(dep_time)),
ultimo_vuelo = last(!is.na(dep_time)))
flights %>% group_by(day) %>%
summarise(primer_vuelo = first(na.rm(dep_time)),
ultimo_vuelo = last(!is.na(dep_time)))
flights %>% group_by(day) %>%
summarise(primer_vuelo = first(dep_time, na.rm = T),
ultimo_vuelo = last(!is.na(dep_time)))
flights %>% group_by(day) %>%
summarise(primer_vuelo = first(dep_time),
ultimo_vuelo = last(dep_time))
no_cancelados %>% group_by(day) %>%
summarise(primer_vuelo = first(dep_time),
ultimo_vuelo = last(dep_time))
no_cancelados <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
no_cancelados %>% group_by(day) %>%
summarise(primer_vuelo = first(dep_time),
ultimo_vuelo = last(dep_time))
flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay)) %>%
group_by(day) %>%
summarise(primer_vuelo = first(dep_time),
ultimo_vuelo = last(dep_time))
flights %>%
group_by(dest) %>%
count(carrier)
flights %>%
group_by(dest, carrier) %>%
summarise(vuelos = n())
flights %>%
group_by(dest, carrier) %>%
summarise(vuelos = n())
flights %>%
group_by(dest) %>%
summarise(vuelos = count(carrier))
flights %>%
group_by(dest) %>%
summarise(vuelos = n(carrier))
flights %>%
group_by(dest) %>%
count(carrier)
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest)
flights %>%
group_by(dest) %>%
count(carrier)
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange()
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange(n)
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange(n, desc(n))
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange(desc(n))
(retraso_salida <- flights %>%
group_by(dest) %>%
summarise(num_vuelos = n(),
dist_media = mean(distance, na.rm = TRUE),
ret_medio = mean(dep_delay, na.rm = TRUE)
) %>%
filter(num_vuelos > 20, dest != "HNL"))
retraso_salida %>%
ggplot(aes(x = dist_media, y = ret_medio)) +
geom_point(aes(size = num_vuelos), alpha = 1/3) +
geom_smooth(se = FALSE)
(retraso_salida <- flights %>%
group_by(dest) %>%
summarise(num_vuelos = n(),
dist_media = mean(distance, na.rm = TRUE),
ret_medio_salida = mean(dep_delay, na.rm = TRUE)
) %>%
filter(num_vuelos > 20, dest != "HNL"))
retraso_salida %>%
ggplot(aes(x = dist_media, y = ret_medio_salida)) +
geom_point(aes(size = num_vuelos), alpha = 1/3) +
geom_smooth(se = FALSE)
library(tidyverse)
library(forecats) # Dentro de tidyverse
library(forcats) # Dentro de tidyverse
gss_cat
head(gss_cat) # Datos
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
head(1)
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
first()
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n))
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
slice_head()
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
slice_head() # head(1) también habría valido
gss_cat %>%
count(partyid) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
slice_head()
gss_cat <- gss_cat %>%
select_if(is.factor)
gss_cat %>%
select_if(is.factor)
head(gss_cat) # Datos
library(tidyverse) # forcats esta dentro
head(gss_cat) # Datos
library(tidyverse) # forcats esta dentro
head(gss_cat) # Datos
library(tidyverse) # forcats esta dentro
head(gss_cat) # Datos
gss_cat %>%
select_if(is.factor)
gss_cat %>%
select_if(is.factor) %>%
colnames()
# Marital
levels(gss_cat[["marital"]])
gss_cat %>%
select(tvhours) %>%
summary
head(gss_cat) # Datos
str(gss_cat)
gss_cat %>%
select(tvhours) %>%
summary
gss_cat %>%
select(tvhours) %>% mean
gss_cat %>%
select(tvhours) %>% summarise(mean)
gss_cat %>%
summarise(promedio = mean(tvhours))
gss_cat %>%
summarise(promedio = mean(tvhours))
gss_cat %>%
summarise(promedio = mean(tvhours, na.rm = T))
gss_cat %>%
select(tvhours) %>%
summary
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>%
ggplot(aes(x = tvhours)) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
ggplot(aes(x = !is.na(tvhours))) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>%
ggplot(aes(x = !is.na(tvhours))) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>%
ggplot(aes(x = tvhours)) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>% # Filtramos los NA
ggplot(aes(x = tvhours)) +
geom_histogram()
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>% # Filtramos los NA
ggplot(aes(x = tvhours)) +
geom_histogram(bins = 24)
gss_cat %>% filter(partyid)
gss_cat %>% select(partyid)
gss_cat %>% select(partyid) %>%
levels
gss_cat %>% select(partyid) %>%
levels()
gss_cat %>% filter(!is.na(partyid)) %>%
count(partyid, sort = TRUE)
# Usamos fct_collapse para crear categorías
# Democrat: "Not str democrat", "Strong democrat"
# Republican: "Strong republican", "Not str republican"
# Independent: "Ind,near rep", "Independent", "Ind,near dem"
gss_cat %>%
# Usamos fct_collapse para crear categorías
# Democrat: "Not str democrat", "Strong democrat"
# Republican: "Strong republican", "Not str republican"
# Independent: "Ind,near rep", "Independent", "Ind,near dem"
gss_cat %>%
gss_cat %>%
mutate(partyid = fct_collapse(partyid, dem = c("Not str democrat", "Strong democrat"),
rep = c("Strong republican", "Not str republican"),
ind = c("Ind,near rep", "Independent", "Ind,near dem"))) %>%
count(year, partyid) %>% # Seleccionamos por año
group_by(year) %>% # Agurpamos por año
mutate(prop = n / sum(n)) %>% # Calculamos la proporción
ggplot(aes(
x = year, y = p,
colour = fct_reorder2(partyid, year, p)
)) +
geom_point() +
geom_line() +
labs(colour = "Party ID."
# Usamos fct_collapse para crear categorías
# Democrat: "Not str democrat", "Strong democrat"
# Republican: "Strong republican", "Not str republican"
# Independent: "Ind,near rep", "Independent", "Ind,near dem"
gss_cat %>%
mutate(partyid = fct_collapse(partyid, dem = c("Not str democrat", "Strong democrat"),
rep = c("Strong republican", "Not str republican"),
ind = c("Ind,near rep", "Independent", "Ind,near dem"))) %>%
count(year, partyid) %>% # Seleccionamos por año
group_by(year) %>% # Agurpamos por año
mutate(prop = n / sum(n)) %>% # Calculamos la proporción
ggplot(aes(
x = year, y = p,
colour = fct_reorder2(partyid, year, p)
)) +
geom_point() +
geom_line() +
labs(colour = "Party ID.")
dataset %>%
select_if(is.numeric) %>%
map(sd)
source('C:/Users/albac/Desktop/MatEst/TFG/TFGAlba/dataformatdesc.R', echo=TRUE)
setwd("C:/Users/albac/Desktop/MatEst/TFG/TFGAlba")
library(tidyverse)
library(magrittr)
data1 = read_csv("data/ADNIMERGE_May15.2014.csv")
data2 = read_csv("data/UPENN_CSF Biomarkers_baseline_May15.2014.csv")
data1 %<>%
filter(VISCODE == "bl")
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(dataset$DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
str(dataset)
summary(dataset)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(dataset$DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl))
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(dataset$DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(dataset$DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(dataset$DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
data1 = read_csv("data/ADNIMERGE_May15.2014.csv")
data2 = read_csv("data/UPENN_CSF Biomarkers_baseline_May15.2014.csv")
data1 %<>%
filter(VISCODE == "bl")
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(dataset$DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
data1 = read_csv("data/ADNIMERGE_May15.2014.csv")
data2 = read_csv("data/UPENN_CSF Biomarkers_baseline_May15.2014.csv")
data1 %<>%
filter(VISCODE == "bl")
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
str(dataset)
summary(dataset)
dataset %>%
select_if(is.numeric) %>%
map(sd)
dataset %>%
select_if(is.factor) %>%
map(table) %>% map(prop.table)
levels(dataset$DX)
str(dataset)
dataset %>%
select_if(is.factor) %>%
map(table) %>% map(prop.table)
library(cluster)
?agnes
agnclus <- agnes(dataset, metric = "euclidean",
stand = FALSE, method="complete")
# stand = FALSE porque no queremos estandarizar
summary(agnclus)
plot(agnclus, main=paste("Agnes:",agnclus$method,sep=""))
agnclus$ac
plot(agnclus, main=paste("Agnes:",agnclus$method,sep=""))
datasetn <- dataset %>%
select_if(is.numeric)
agnclus <- agnes(datasetn, metric = "euclidean",
stand = FALSE, method="complete")
# stand = FALSE porque no queremos estandarizar
summary(agnclus)
plot(agnclus, main=paste("Agnes:",agnclus$method,sep=""))
