flights %>%
group_by(dest) %>%
summarise(vuelos = count(carrier))
flights %>%
group_by(dest) %>%
summarise(vuelos = n(carrier))
flights %>%
group_by(dest) %>%
count(carrier)
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest)
flights %>%
group_by(dest) %>%
count(carrier)
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange()
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange(n)
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange(n, desc(n))
flights %>%
group_by(dest) %>%
count(carrier) %>%
count(dest) %>% arrange(desc(n))
(retraso_salida <- flights %>%
group_by(dest) %>%
summarise(num_vuelos = n(),
dist_media = mean(distance, na.rm = TRUE),
ret_medio = mean(dep_delay, na.rm = TRUE)
) %>%
filter(num_vuelos > 20, dest != "HNL"))
retraso_salida %>%
ggplot(aes(x = dist_media, y = ret_medio)) +
geom_point(aes(size = num_vuelos), alpha = 1/3) +
geom_smooth(se = FALSE)
(retraso_salida <- flights %>%
group_by(dest) %>%
summarise(num_vuelos = n(),
dist_media = mean(distance, na.rm = TRUE),
ret_medio_salida = mean(dep_delay, na.rm = TRUE)
) %>%
filter(num_vuelos > 20, dest != "HNL"))
retraso_salida %>%
ggplot(aes(x = dist_media, y = ret_medio_salida)) +
geom_point(aes(size = num_vuelos), alpha = 1/3) +
geom_smooth(se = FALSE)
library(tidyverse)
library(forecats) # Dentro de tidyverse
library(forcats) # Dentro de tidyverse
gss_cat
head(gss_cat) # Datos
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
head(1)
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
first()
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n))
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
slice_head()
gss_cat %>%
count(relig) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
slice_head() # head(1) también habría valido
gss_cat %>%
count(partyid) %>% # Hacemos que cuente las religiones
arrange(desc(n)) %>% # Ordenamos descendentemente
slice_head()
gss_cat <- gss_cat %>%
select_if(is.factor)
gss_cat %>%
select_if(is.factor)
head(gss_cat) # Datos
library(tidyverse) # forcats esta dentro
head(gss_cat) # Datos
library(tidyverse) # forcats esta dentro
head(gss_cat) # Datos
library(tidyverse) # forcats esta dentro
head(gss_cat) # Datos
gss_cat %>%
select_if(is.factor)
gss_cat %>%
select_if(is.factor) %>%
colnames()
# Marital
levels(gss_cat[["marital"]])
gss_cat %>%
select(tvhours) %>%
summary
head(gss_cat) # Datos
str(gss_cat)
gss_cat %>%
select(tvhours) %>%
summary
gss_cat %>%
select(tvhours) %>% mean
gss_cat %>%
select(tvhours) %>% summarise(mean)
gss_cat %>%
summarise(promedio = mean(tvhours))
gss_cat %>%
summarise(promedio = mean(tvhours))
gss_cat %>%
summarise(promedio = mean(tvhours, na.rm = T))
gss_cat %>%
select(tvhours) %>%
summary
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>%
ggplot(aes(x = tvhours)) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
ggplot(aes(x = !is.na(tvhours))) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>%
ggplot(aes(x = !is.na(tvhours))) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>%
ggplot(aes(x = tvhours)) +
geom_histogram(binwidth = 1)
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>% # Filtramos los NA
ggplot(aes(x = tvhours)) +
geom_histogram()
# Dibujamos la distribución
gss_cat %>%
filter(!is.na(tvhours)) %>% # Filtramos los NA
ggplot(aes(x = tvhours)) +
geom_histogram(bins = 24)
gss_cat %>% filter(partyid)
gss_cat %>% select(partyid)
gss_cat %>% select(partyid) %>%
levels
gss_cat %>% select(partyid) %>%
levels()
gss_cat %>% filter(!is.na(partyid)) %>%
count(partyid, sort = TRUE)
# Usamos fct_collapse para crear categorías
# Democrat: "Not str democrat", "Strong democrat"
# Republican: "Strong republican", "Not str republican"
# Independent: "Ind,near rep", "Independent", "Ind,near dem"
gss_cat %>%
# Usamos fct_collapse para crear categorías
# Democrat: "Not str democrat", "Strong democrat"
# Republican: "Strong republican", "Not str republican"
# Independent: "Ind,near rep", "Independent", "Ind,near dem"
gss_cat %>%
gss_cat %>%
mutate(partyid = fct_collapse(partyid, dem = c("Not str democrat", "Strong democrat"),
rep = c("Strong republican", "Not str republican"),
ind = c("Ind,near rep", "Independent", "Ind,near dem"))) %>%
count(year, partyid) %>% # Seleccionamos por año
group_by(year) %>% # Agurpamos por año
mutate(prop = n / sum(n)) %>% # Calculamos la proporción
ggplot(aes(
x = year, y = p,
colour = fct_reorder2(partyid, year, p)
)) +
geom_point() +
geom_line() +
labs(colour = "Party ID."
# Usamos fct_collapse para crear categorías
# Democrat: "Not str democrat", "Strong democrat"
# Republican: "Strong republican", "Not str republican"
# Independent: "Ind,near rep", "Independent", "Ind,near dem"
gss_cat %>%
mutate(partyid = fct_collapse(partyid, dem = c("Not str democrat", "Strong democrat"),
rep = c("Strong republican", "Not str republican"),
ind = c("Ind,near rep", "Independent", "Ind,near dem"))) %>%
count(year, partyid) %>% # Seleccionamos por año
group_by(year) %>% # Agurpamos por año
mutate(prop = n / sum(n)) %>% # Calculamos la proporción
ggplot(aes(
x = year, y = p,
colour = fct_reorder2(partyid, year, p)
)) +
geom_point() +
geom_line() +
labs(colour = "Party ID.")
library(tidyverse)
library(ggpubr)
library(shapr)
library(caret)
library(randomForest)
dataset <- read_csv("data/datasetADNI.csv")
dataset <- dataset[,-1] # Removing ID
setwd("C:/Users/albac/Desktop/MatEst/TFG/TFGAlba")
dataset <- read_csv("data/datasetADNI.csv")
dataset <- dataset[,-1] # Removing ID
head(dataset)
dataset$APOE4 = as.factor(dataset$APOE4)
dataset$PTGENDER = as.factor(dataset$PTGENDER)
dataset$DX = as.factor(dataset$DX)
head(dataset)
# Fixing covariables and response variable
x_var <- c("FDG","ABETA","PTAU","APOE4","PTGENDER","AGE","PTEDUCAT")
y_var <- "DX"
# Splitting in train-test (80%-20%) ----
set.seed(2022)
train_index <- caret::createDataPartition(dataset$DX, p = .8, list = FALSE, times = 1)
# Training data
x_train <- as.matrix(dataset[train_index, x_var])
y_train_nc <- as.matrix(dataset[train_index, y_var]) # not centered
y_train <- y_train_nc - mean(y_train_nc) # Tengo covariables categóricas
# Random forest ----
model <- randomForest(x = x_train, y = y_train_nc, ntree=500)
# Random forest ----
model <- randomForest(x = x_train_nc, y = y_train_nc, ntree=500)
# Random forest ----
model <- randomForest(x = x_train, y = y_train_nc, ntree=500)
head(dataset)
# Training data
x_train <- as.matrix(dataset[train_index, x_var])
x_train
# Random forest ----
model <- randomForest(x = x_train[,-5], y = y_train_nc, ntree=500)
y_train_nc
unclass(dataset$DX)
pull(unclass(dataset$DX))
head(dataset)
dataset$APOE4 = unclass(dataset$APOE4)
dataset$PTGENDER = unclass(dataset$PTGENDER)
dataset$DX = unclass(dataset$DX)
head(dataset)
# Fixing covariables and response variable
x_var <- c("FDG","ABETA","PTAU","APOE4","PTGENDER","AGE","PTEDUCAT")
y_var <- "DX"
# Splitting in train-test (80%-20%) ----
set.seed(2022)
train_index <- caret::createDataPartition(dataset$DX, p = .8, list = FALSE, times = 1)
# Training data
x_train <- as.matrix(dataset[train_index, x_var])
y_train_nc <- as.matrix(dataset[train_index, y_var]) # not centered
y_train <- y_train_nc - mean(y_train_nc) # Tengo covariables categóricas
# Test data
x_test <- as.matrix(dataset[-train_index, x_var])
y_test_nc <- as.matrix(dataset[-train_index, y_var]) # not centered
y_test <- y_test_nc - mean(y_train_nc) # Tengo covariables categóricas
# Random forest ----
model <- randomForest(x = x_train, y = y_train_nc, ntree=500)
print(model)
explainer_symmetric <- shapr(x_train, model)
head(dataset)
data1 = read_csv("data/ADNIMERGE_May15.2014.csv")
data2 = read_csv("data/UPENN_CSF Biomarkers_baseline_May15.2014.csv")
setwd("C:/Users/albac/Desktop/MatEst/TFG/TFGAlba")
data1 = read_csv("data/ADNIMERGE_May15.2014.csv")
data2 = read_csv("data/UPENN_CSF Biomarkers_baseline_May15.2014.csv")
library(tidyverse)
library(magrittr)
library(cluster)
data1 = read_csv("data/ADNIMERGE_May15.2014.csv")
data2 = read_csv("data/UPENN_CSF Biomarkers_baseline_May15.2014.csv")
data1 %<>%
filter(VISCODE == "bl")
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI"))) %>%
select(-DX.bl)
## Coding factors
dataset$PTGENDER = unclass(dataset$PTGENDER)-1
dataset$DX = unclass(dataset$DX)
head(dataset)
levels(DX)
unclass(dataset$DX)
dataset$DX = unclass(dataset$DX)-1
head(dataset)
dataset$PTGENDER = as.factor(dataset$PTGENDER)
dataset$DX = as.factor(dataset$DX)
head(dataset)
# Saving dataset for further use
write_csv(dataset, "data/datasetADNI.csv")
str(dataset)
summary(dataset)
dataset %>%
select_if(is.numeric) %>%
map(sd)
dataset %>%
select_if(is.factor) %>%
map(table) %>% map(prop.table)
agnclus <- agnes(dataset, metric = "euclidean",
stand = FALSE, method="complete")
# stand = FALSE porque no queremos estandarizar
summary(agnclus)
plot(agnclus, main=paste("Agnes:",agnclus$method,sep=""))
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI")),
DXB = fct_collapse(DX, MCI = c("EMCI", "LMCI", "AD"))) %>%
select(-DX.bl)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI")),
DXB = fct_collapse(DX, DP = c("EMCI", "LMCI", "AD"))) %>%
select(-DX.bl)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI")),
DXB = fct_collapse(DX, DP = c("MCI", "AD"))) %>%
select(-DX.bl)
## Coding factors
dataset$PTGENDER = unclass(dataset$PTGENDER)-1
dataset$PTGENDER = as.factor(dataset$PTGENDER)
dataset$DX = unclass(dataset$DX)-1
dataset$DX = as.factor(dataset$DX)
dataset$DXB = unclass(dataset$DXB)-1
dataset$DXB = as.factor(dataset$DXB)
head(dataset)
dataset$DXB = unclass(dataset$DXB)-1
unclass(dataset$DXB)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI")),
DXB = fct_collapse(DX, DP = c("MCI", "AD"))) %>%
select(-DX.bl)
unclass(dataset$DXB)-1
dataset %>%
select_if(is.factor) %>%
map(table) %>% map(prop.table)
## Combining both datasets and selecting relevant variables
dataset <- inner_join(data1, data2, by = "RID") %>%
select(RID, FDG, ABETA, PTAU, APOE4, PTGENDER, AGE, PTEDUCAT, DX.bl) %>%
na.omit() %>%
mutate(APOE4 = as.factor(APOE4),
PTGENDER = as.factor(PTGENDER),
DX = as.factor(DX.bl)) %>%
mutate(DX = fct_collapse(DX, MCI = c("EMCI", "LMCI")),
DXB = fct_collapse(DX, DP = c("MCI", "AD"))) %>%
select(-DX.bl)
## Coding factors
dataset$PTGENDER = unclass(dataset$PTGENDER)-1
dataset$PTGENDER = as.factor(dataset$PTGENDER)
dataset$DX = unclass(dataset$DX)-1
dataset$DX = as.factor(dataset$DX)
dataset$DXB = unclass(dataset$DXB)-1
dataset$DXB = as.factor(dataset$DXB)
head(dataset)
# Saving dataset for further use
write_csv(dataset, "data/datasetADNI.csv")
library(tidyverse)
library(ggpubr)
library(shapr)
library(caret)
library(randomForest)
# Installing the causally enhanced shapr package from source
devtools::install_local("shapr-master", dependencies = TRUE)
dataset <- read_csv("data/datasetADNI.csv")
dataset <- dataset[,-1] # Removing ID
head(dataset)
dataset$APOE4 = as.factor(dataset$APOE4)
dataset$PTGENDER = as.factor(dataset$PTGENDER)
dataset$DX = as.factor(dataset$DX)
head(dataset)
# Fixing covariables and response variable
x_var <- c("FDG","ABETA","PTAU","APOE4","PTGENDER","AGE","PTEDUCAT")
y_var <- "DXB" # Binary classification
# Splitting in train-test (80%-20%) ----
set.seed(2022)
train_index <- caret::createDataPartition(dataset$DX, p = .8, list = FALSE, times = 1)
# Training data
x_train <- as.matrix(dataset[train_index, x_var])
y_train_nc <- as.matrix(dataset[train_index, y_var]) # not centered
y_train <- y_train_nc - mean(y_train_nc) # Tengo covariables categóricas
# Test data
x_test <- as.matrix(dataset[-train_index, x_var])
y_test_nc <- as.matrix(dataset[-train_index, y_var]) # not centered
y_test <- y_test_nc - mean(y_train_nc) # Tengo covariables categóricas
modelxgb <- xgboost(data = x_train, label = y_train, nround = 100, verbose = FALSE)
library(xgboost)
modelxgb <- xgboost(data = x_train, label = y_train, nround = 100, verbose = FALSE)
x_train
dataset <- read_csv("data/datasetADNI.csv")
dataset <- dataset[,-1] # Removing ID
# Training data
x_train <- as.matrix(dataset[train_index, x_var])
y_train_nc <- as.matrix(dataset[train_index, y_var]) # not centered
y_train <- y_train_nc - mean(y_train_nc) # Tengo covariables categóricas
# Test data
x_test <- as.matrix(dataset[-train_index, x_var])
y_test_nc <- as.matrix(dataset[-train_index, y_var]) # not centered
y_test <- y_test_nc - mean(y_train_nc) # Tengo covariables categóricas
modelxgb <- xgboost(data = x_train, label = y_train, nround = 100, verbose = FALSE)
print(modelxgb)
explainer_symmetric <- shapr(x_train, model)
explainer_symmetric <- shapr(x_train, modelxgb)
p <- mean(y_train)
# a. We compute the causal Shapley values on a given partial order (see paper)
partial_order <- list(1, c(2, 3), c(4:7)) # Poner el nuevo
explanation_causal <- explain(
x_test,
approach = "causal",
explainer = explainer_symmetric,
prediction_zero = p,
ordering = partial_order,
confounding = c(FALSE, TRUE, FALSE),
seed = 2020
)
sina_causal <- sina_plot(explanation_causal)
# For sina plotting capabilities
source("shapr-aster/R/sina_plot.R")
# For sina plotting capabilities
source("shapr-master/R/sina_plot.R")
# For sina plotting capabilities
source("extra/sina_plot.R")
sina_causal <- sina_plot(explanation_causal)
library(ggforce)
install.packages
install.packages("ggforce")
# For sina plotting capabilities
source("extra/sina_plot.R")
sina_causal <- sina_plot(explanation_causal)
sina_causal
# save limits of sina_causal plot for comparing against marginal and asymmetric
ylim_causal <- sina_causal$coordinates$limits$y
# b. For computing marginal Shapley values, we assume one component with confounding
explanation_marginal <- explain(
x_test,
approach = "causal",
explainer = explainer_symmetric,
prediction_zero = p,
ordering = list(c(1:7)),
confounding = TRUE,
seed = 2020
)
sina_marginal <- sina_plot(explanation_marginal) +
coord_flip(ylim = ylim_causal) + ylab("Marginal Shapley value (impact on model output)")
sina_marginal
# c. Finally, we compute the asymmetric Shapley values for the same partial order
explainer_asymmetric <- shapr(x_train, model, asymmetric = TRUE, ordering = partial_order)
p <- mean(y_train)
explanation_asymmetric <- explain(
x_test,
approach = "gaussian",
explainer = explainer_asymmetric,
prediction_zero = p,
ordering = partial_order,
asymmetric = TRUE,
seed = 2020
)
# c. Finally, we compute the asymmetric Shapley values for the same partial order
explainer_asymmetric <- shapr(x_train, modelxgb, asymmetric = TRUE, ordering = partial_order)
p <- mean(y_train)
explanation_asymmetric <- explain(
x_test,
approach = "gaussian",
explainer = explainer_asymmetric,
prediction_zero = p,
ordering = partial_order,
asymmetric = TRUE,
seed = 2020
)
sina_asymmetric <- sina_plot(explanation_asymmetric) +
coord_flip(ylim = ylim_causal) + ylab("Asymmetric conditional Shapley value (impact on model output)")
sina_asymmetric
explanation_asymmetric_causal <- explain(
x_test,
approach = "causal",
explainer = explainer_asymmetric,
prediction_zero = p,
asymmetric = TRUE,
ordering = partial_order,
confounding = c(FALSE, TRUE, FALSE),
seed = 2020
)
sina_asymmetric_causal <- sina_plot(explanation_asymmetric_causal) +
coord_flip(ylim = ylim_causal) + ylab("Asymmetric causal Shapley value (impact on model output)")
